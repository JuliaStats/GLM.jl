var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"DocTestSetup = quote\n    using CategoricalArrays, DataFrames, Distributions, GLM, RDatasets\nend","category":"page"},{"location":"api/#Types-defined-in-the-package","page":"API","title":"Types defined in the package","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"LinearModel\nGLM.DensePredChol\nGLM.DensePredQR\nGLM.LmResp\nGLM.GlmResp\nGLM.LinPred\nGLM.ModResp","category":"page"},{"location":"api/#GLM.LinearModel","page":"API","title":"GLM.LinearModel","text":"LinearModel\n\nA combination of a LmResp and a LinPred\n\nMembers\n\nrr: a LmResp object\npp: a LinPred object\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.DensePredChol","page":"API","title":"GLM.DensePredChol","text":"DensePredChol{T}\n\nA LinPred type with a dense Cholesky factorization of X'X\n\nMembers\n\nX: model matrix of size n × p with n ≥ p.  Should be full column rank.\nbeta0: base coefficient vector of length p\ndelbeta: increment to coefficient vector, also of length p\nscratchbeta: scratch vector of length p, used in linpred! method\nchol: a Cholesky object created from X'X, possibly using row weights.\nscratchm1: scratch Matrix{T} of the same size as X\nscratchm2: scratch Matrix{T} os the same size as X'X\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.DensePredQR","page":"API","title":"GLM.DensePredQR","text":"DensePredQR\n\nA LinPred type with a dense, unpivoted QR decomposition of X\n\nMembers\n\nX: Model matrix of size n × p with n ≥ p.  Should be full column rank.\nbeta0: base coefficient vector of length p\ndelbeta: increment to coefficient vector, also of length p\nscratchbeta: scratch vector of length p, used in linpred! method\nqr: a QRCompactWY object created from X, with optional row weights.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.LmResp","page":"API","title":"GLM.LmResp","text":"LmResp\n\nEncapsulates the response for a linear model\n\nMembers\n\nmu: current value of the mean response vector or fitted value\noffset: optional offset added to the linear predictor to form mu\nwts: optional vector of prior frequency (a.k.a. case) weights for observations\ny: observed response vector\n\nEither or both offset and wts may be of length 0\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.GlmResp","page":"API","title":"GLM.GlmResp","text":"GlmResp\n\nThe response vector and various derived vectors in a generalized linear model.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.LinPred","page":"API","title":"GLM.LinPred","text":"LinPred\n\nAbstract type representing a linear predictor\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.ModResp","page":"API","title":"GLM.ModResp","text":"ModResp\n\nAbstract type representing a model response vector\n\n\n\n\n\n","category":"type"},{"location":"api/#Constructors-for-models","page":"API","title":"Constructors for models","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"The most general approach to fitting a model is with the fit function, as in","category":"page"},{"location":"api/","page":"API","title":"API","text":"julia> using Random\n\njulia> fit(LinearModel, hcat(ones(10), 1:10), randn(MersenneTwister(12321), 10))\nLinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}:\n\nCoefficients:\n────────────────────────────────────────────────────────────────\n        Coef.  Std. Error      t  Pr(>|t|)  Lower 95%  Upper 95%\n────────────────────────────────────────────────────────────────\nx1   0.717436    0.775175   0.93    0.3818  -1.07012    2.50499\nx2  -0.152062    0.124931  -1.22    0.2582  -0.440153   0.136029\n────────────────────────────────────────────────────────────────","category":"page"},{"location":"api/","page":"API","title":"API","text":"This model can also be fit as","category":"page"},{"location":"api/","page":"API","title":"API","text":"julia> using Random\n\njulia> lm(hcat(ones(10), 1:10), randn(MersenneTwister(12321), 10))\nLinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}:\n\nCoefficients:\n────────────────────────────────────────────────────────────────\n        Coef.  Std. Error      t  Pr(>|t|)  Lower 95%  Upper 95%\n────────────────────────────────────────────────────────────────\nx1   0.717436    0.775175   0.93    0.3818  -1.07012    2.50499\nx2  -0.152062    0.124931  -1.22    0.2582  -0.440153   0.136029\n────────────────────────────────────────────────────────────────","category":"page"},{"location":"api/","page":"API","title":"API","text":"lm\nglm\nnegbin\nfit","category":"page"},{"location":"api/#GLM.lm","page":"API","title":"GLM.lm","text":"lm(formula, data, allowrankdeficient=false;\n   [wts::AbstractVector], dropcollinear::Bool=true)\nlm(X::AbstractMatrix, y::AbstractVector;\n   wts::AbstractVector=similar(y, 0), dropcollinear::Bool=true)\n\nFit a linear model to data. An alias for fit(LinearModel, X, y; wts=wts, dropcollinear=dropcollinear)\n\nIn the first method, formula must be a StatsModels.jl Formula object and data a table (in the Tables.jl definition, e.g. a data frame). In the second method, X must be a matrix holding values of the independent variable(s) in columns (including if appropriate the intercept), and y must be a vector holding values of the dependent variable.\n\nThe keyword argument wts can be a Vector specifying frequency weights for observations. Such weights are equivalent to repeating each observation a number of times equal to its weight. Do note that this interpretation gives equal point estimates but different standard errors from analytical (a.k.a. inverse variance) weights and from probability (a.k.a. sampling) weights which are the default in some other software.\n\ndropcollinear controls whether or not lm accepts a model matrix which is less-than-full rank. If true (the default), only the first of each set of linearly-dependent columns is used. The coefficient for redundant linearly dependent columns is 0.0 and all associated statistics are set to NaN.\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.glm","page":"API","title":"GLM.glm","text":"glm(formula, data,\n    distr::UnivariateDistribution, link::Link = canonicallink(d); <keyword arguments>)\nglm(X::AbstractMatrix, y::AbstractVector,\n    distr::UnivariateDistribution, link::Link = canonicallink(d); <keyword arguments>)\n\nFit a generalized linear model to data. Alias for fit(GeneralizedLinearModel, ...).\n\nIn the first method, formula must be a StatsModels.jl Formula object and data a table (in the Tables.jl definition, e.g. a data frame). In the second method, X must be a matrix holding values of the independent variable(s) in columns (including if appropriate the intercept), and y must be a vector holding values of the dependent variable. In both cases, distr must specify the distribution, and link may specify the link function (if omitted, it is taken to be the canonical link for distr; see Link for a list of built-in links).\n\nKeyword Arguments\n\ndofit::Bool=true: Determines whether model will be fit\nwts::Vector=similar(y,0): Prior frequency (a.k.a. case) weights of observations. Such weights are equivalent to repeating each observation a number of times equal to its weight. Do note that this interpretation gives equal point estimates but different standard errors from analytical (a.k.a. inverse variance) weights and from probability (a.k.a. sampling) weights which are the default in some other software. Can be length 0 to indicate no weighting (default).\noffset::Vector=similar(y,0): offset added to Xβ to form eta.  Can be of length 0\nverbose::Bool=false: Display convergence information for each iteration\nmaxiter::Integer=30: Maximum number of iterations allowed to achieve convergence\natol::Real=1e-6: Convergence is achieved when the relative change in deviance is less than max(rtol*dev, atol).\nrtol::Real=1e-6: Convergence is achieved when the relative change in deviance is less than max(rtol*dev, atol).\nminstepfac::Real=0.001: Minimum line step fraction. Must be between 0 and 1.\nstart::AbstractVector=nothing: Starting values for beta. Should have the same length as the number of columns in the model matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.negbin","page":"API","title":"GLM.negbin","text":"negbin(formula, data, [link::Link];\n       <keyword arguments>)\nnegbin(X::AbstractMatrix, y::AbstractVector, [link::Link];\n       <keyword arguments>)\n\nFit a negative binomial generalized linear model to data, while simultaneously estimating the shape parameter θ. Extra arguments and keyword arguments will be passed to glm.\n\nIn the first method, formula must be a StatsModels.jl Formula object and data a table (in the Tables.jl definition, e.g. a data frame). In the second method, X must be a matrix holding values of the independent variable(s) in columns (including if appropriate the intercept), and y must be a vector holding values of the dependent variable. In both cases, link may specify the link function (if omitted, it is taken to be NegativeBinomial(θ)).\n\nKeyword Arguments\n\ninitialθ::Real=Inf: Starting value for shape parameter θ. If it is Inf then the initial value will be estimated by fitting a Poisson distribution.\nmaxiter::Integer=30: See maxiter for glm\natol::Real=1.0e-6: See atol for glm\nrtol::Real=1.0e-6: See rtol for glm\nverbose::Bool=false: See verbose for glm\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.fit","page":"API","title":"StatsAPI.fit","text":"fit(LinearModel, formula, data, allowrankdeficient=false;\n   [wts::AbstractVector], dropcollinear::Bool=true)\nfit(LinearModel, X::AbstractMatrix, y::AbstractVector;\n    wts::AbstractVector=similar(y, 0), dropcollinear::Bool=true)\n\nFit a linear model to data.\n\nIn the first method, formula must be a StatsModels.jl Formula object and data a table (in the Tables.jl definition, e.g. a data frame). In the second method, X must be a matrix holding values of the independent variable(s) in columns (including if appropriate the intercept), and y must be a vector holding values of the dependent variable.\n\nThe keyword argument wts can be a Vector specifying frequency weights for observations. Such weights are equivalent to repeating each observation a number of times equal to its weight. Do note that this interpretation gives equal point estimates but different standard errors from analytical (a.k.a. inverse variance) weights and from probability (a.k.a. sampling) weights which are the default in some other software.\n\ndropcollinear controls whether or not lm accepts a model matrix which is less-than-full rank. If true (the default), only the first of each set of linearly-dependent columns is used. The coefficient for redundant linearly dependent columns is 0.0 and all associated statistics are set to NaN.\n\n\n\n\n\nfit(GeneralizedLinearModel, formula, data,\n    distr::UnivariateDistribution, link::Link = canonicallink(d); <keyword arguments>)\nfit(GeneralizedLinearModel, X::AbstractMatrix, y::AbstractVector,\n    distr::UnivariateDistribution, link::Link = canonicallink(d); <keyword arguments>)\n\nFit a generalized linear model to data.\n\nIn the first method, formula must be a StatsModels.jl Formula object and data a table (in the Tables.jl definition, e.g. a data frame). In the second method, X must be a matrix holding values of the independent variable(s) in columns (including if appropriate the intercept), and y must be a vector holding values of the dependent variable. In both cases, distr must specify the distribution, and link may specify the link function (if omitted, it is taken to be the canonical link for distr; see Link for a list of built-in links).\n\nKeyword Arguments\n\ndofit::Bool=true: Determines whether model will be fit\nwts::Vector=similar(y,0): Prior frequency (a.k.a. case) weights of observations. Such weights are equivalent to repeating each observation a number of times equal to its weight. Do note that this interpretation gives equal point estimates but different standard errors from analytical (a.k.a. inverse variance) weights and from probability (a.k.a. sampling) weights which are the default in some other software. Can be length 0 to indicate no weighting (default).\noffset::Vector=similar(y,0): offset added to Xβ to form eta.  Can be of length 0\nverbose::Bool=false: Display convergence information for each iteration\nmaxiter::Integer=30: Maximum number of iterations allowed to achieve convergence\natol::Real=1e-6: Convergence is achieved when the relative change in deviance is less than max(rtol*dev, atol).\nrtol::Real=1e-6: Convergence is achieved when the relative change in deviance is less than max(rtol*dev, atol).\nminstepfac::Real=0.001: Minimum line step fraction. Must be between 0 and 1.\nstart::AbstractVector=nothing: Starting values for beta. Should have the same length as the number of columns in the model matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#Model-methods","page":"API","title":"Model methods","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"StatsBase.deviance\nGLM.dispersion\nGLM.ftest\nGLM.installbeta!\nStatsBase.nobs\nStatsBase.nulldeviance\nStatsBase.predict\nStatsModels.isnested","category":"page"},{"location":"api/#StatsAPI.deviance","page":"API","title":"StatsAPI.deviance","text":"deviance(obj::LinearModel)\n\nFor linear models, the deviance is equal to the residual sum of squares (RSS).\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.dispersion","page":"API","title":"GLM.dispersion","text":"dispersion(m::AbstractGLM, sqr::Bool=false)\n\nReturn the estimated dispersion (or scale) parameter for a model's distribution, generally written σ for linear models and ϕ for generalized linear models. It is, by definition, equal to 1 for the Bernoulli, Binomial, and Poisson families.\n\nIf sqr is true, the squared dispersion parameter is returned.\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.ftest","page":"API","title":"GLM.ftest","text":"ftest(mod::LinearModel)\n\nPerform an F-test to determine whether model mod fits significantly better than the null model (i.e. which includes only the intercept).\n\njulia> dat = DataFrame(Result=[1.1, 1.2, 1, 2.2, 1.9, 2, 0.9, 1, 1, 2.2, 2, 2],\n                       Treatment=[1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2]);\n\n\njulia> model = lm(@formula(Result ~ 1 + Treatment), dat);\n\n\njulia> ftest(model.model)\nF-test against the null model:\nF-statistic: 241.62 on 12 observations and 1 degrees of freedom, p-value: <1e-07\n\n\n\n\n\nftest(mod::LinearModel...; atol::Real=0.0)\n\nFor each sequential pair of linear models in mod..., perform an F-test to determine if the one model fits significantly better than the other. Models must have been fitted on the same data, and be nested either in forward or backward direction.\n\nA table is returned containing consumed degrees of freedom (DOF), difference in DOF from the preceding model, sum of squared residuals (SSR), difference in SSR from the preceding model, R², difference in R² from the preceding model, and F-statistic and p-value for the comparison between the two models.\n\nnote: Note\nThis function can be used to perform an ANOVA by testing the relative fit of two models to the data\n\nOptional keyword argument atol controls the numerical tolerance when testing whether the models are nested.\n\nExamples\n\nSuppose we want to compare the effects of two or more treatments on some result. Because this is an ANOVA, our null hypothesis is that Result ~ 1 fits the data as well as Result ~ 1 + Treatment.\n\njulia> dat = DataFrame(Result=[1.1, 1.2, 1, 2.2, 1.9, 2, 0.9, 1, 1, 2.2, 2, 2],\n                       Treatment=[1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2],\n                       Other=categorical([1, 1, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1]));\n\n\njulia> nullmodel = lm(@formula(Result ~ 1), dat);\n\n\njulia> model = lm(@formula(Result ~ 1 + Treatment), dat);\n\n\njulia> bigmodel = lm(@formula(Result ~ 1 + Treatment + Other), dat);\n\n\njulia> ftest(nullmodel.model, model.model)\nF-test: 2 models fitted on 12 observations\n──────────────────────────────────────────────────────────────────\n     DOF  ΔDOF     SSR     ΔSSR       R²     ΔR²        F*   p(>F)\n──────────────────────────────────────────────────────────────────\n[1]    2        3.2292           -0.0000\n[2]    3     1  0.1283  -3.1008   0.9603  0.9603  241.6234  <1e-07\n──────────────────────────────────────────────────────────────────\n\njulia> ftest(nullmodel.model, model.model, bigmodel.model)\nF-test: 3 models fitted on 12 observations\n──────────────────────────────────────────────────────────────────\n     DOF  ΔDOF     SSR     ΔSSR       R²     ΔR²        F*   p(>F)\n──────────────────────────────────────────────────────────────────\n[1]    2        3.2292           -0.0000\n[2]    3     1  0.1283  -3.1008   0.9603  0.9603  241.6234  <1e-07\n[3]    5     2  0.1017  -0.0266   0.9685  0.0082    1.0456  0.3950\n──────────────────────────────────────────────────────────────────\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.installbeta!","page":"API","title":"GLM.installbeta!","text":"installbeta!(p::LinPred, f::Real=1.0)\n\nInstall pbeta0 .+= f * p.delbeta and zero out p.delbeta.  Return the updated p.beta0.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.nobs","page":"API","title":"StatsAPI.nobs","text":"nobs(obj::LinearModel)\nnobs(obj::GLM)\n\nFor linear and generalized linear models, returns the number of rows, or, when prior weights are specified, the sum of weights.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.nulldeviance","page":"API","title":"StatsAPI.nulldeviance","text":"nulldeviance(obj::LinearModel)\n\nFor linear models, the deviance of the null model is equal to the total sum of squares (TSS).\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict","page":"API","title":"StatsAPI.predict","text":"predict(mm::LinearModel, newx::AbstractMatrix;\n        interval::Union{Symbol,Nothing} = nothing, level::Real = 0.95)\n\nIf interval is nothing (the default), return a vector with the predicted values for model mm and new data newx. Otherwise, return a vector with the predicted values, as well as vectors with the lower and upper confidence bounds for a given level (0.95 equates alpha = 0.05). Valid values of interval are :confidence delimiting the  uncertainty of the predicted relationship, and :prediction delimiting estimated bounds for new data points.\n\n\n\n\n\npredict(mm::AbstractGLM, newX::AbstractMatrix; offset::FPVector=eltype(newX)[],\n        interval::Union{Symbol,Nothing}=nothing, level::Real = 0.95,\n        interval_method::Symbol = :transformation)\n\nReturn the predicted response of model mm from covariate values newX and, optionally, an offset.\n\nIf interval=:confidence, also return upper and lower bounds for a given coverage level. By default (interval_method = :transformation) the intervals are constructed by applying the inverse link to intervals for the linear predictor. If interval_method = :delta, the intervals are constructed by the delta method, i.e., by linearization of the predicted response around the linear predictor. The :delta method intervals are symmetric around the point estimates, but do not respect natural parameter constraints (e.g., the lower bound for a probability could be negative).\n\n\n\n\n\n","category":"function"},{"location":"api/#Links-and-methods-applied-to-them","page":"API","title":"Links and methods applied to them","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Link\nGLM.Link01\nCauchitLink\nCloglogLink\nIdentityLink\nInverseLink\nInverseSquareLink\nLogitLink\nLogLink\nNegativeBinomialLink\nProbitLink\nSqrtLink\nGLM.linkfun\nGLM.linkinv\nGLM.mueta\nGLM.inverselink\ncanonicallink\nGLM.glmvar\nGLM.mustart\ndevresid\nGLM.dispersion_parameter\nGLM.loglik_obs\nGLM.cancancel","category":"page"},{"location":"api/#GLM.Link","page":"API","title":"GLM.Link","text":"Link\n\nAn abstract type whose subtypes refer to link functions.\n\nGLM currently supports the following links: CauchitLink, CloglogLink, IdentityLink, InverseLink, InverseSquareLink, LogitLink, LogLink, NegativeBinomialLink, ProbitLink, SqrtLink.\n\nSubtypes of Link are required to implement methods for GLM.linkfun, GLM.linkinv, GLM.mueta, and GLM.inverselink.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.Link01","page":"API","title":"GLM.Link01","text":"Link01\n\nAn abstract subtype of Link which are links defined on (0, 1)\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.CauchitLink","page":"API","title":"GLM.CauchitLink","text":"CauchitLink\n\nA Link01 corresponding to the standard Cauchy distribution, Distributions.Cauchy.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.CloglogLink","page":"API","title":"GLM.CloglogLink","text":"CloglogLink\n\nA Link01 corresponding to the extreme value (or log-Weibull) distribution.  The link is the complementary log-log transformation, log(1 - log(-μ)).\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.IdentityLink","page":"API","title":"GLM.IdentityLink","text":"IdentityLink\n\nThe canonical Link for the Normal distribution, defined as η = μ.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.InverseLink","page":"API","title":"GLM.InverseLink","text":"InverseLink\n\nThe canonical Link for Distributions.Gamma distribution, defined as η = inv(μ).\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.InverseSquareLink","page":"API","title":"GLM.InverseSquareLink","text":"InverseSquareLink\n\nThe canonical Link for Distributions.InverseGaussian distribution, defined as η = inv(abs2(μ)).\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.LogitLink","page":"API","title":"GLM.LogitLink","text":"LogitLink\n\nThe canonical Link01 for Distributions.Bernoulli and Distributions.Binomial. The inverse link, linkinv, is the c.d.f. of the standard logistic distribution, Distributions.Logistic.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.LogLink","page":"API","title":"GLM.LogLink","text":"LogLink\n\nThe canonical Link for Distributions.Poisson, defined as η = log(μ).\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.NegativeBinomialLink","page":"API","title":"GLM.NegativeBinomialLink","text":"NegativeBinomialLink\n\nThe canonical Link for Distributions.NegativeBinomial distribution, defined as η = log(μ/(μ+θ)). The shape parameter θ has to be fixed for the distribution to belong to the exponential family.\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.ProbitLink","page":"API","title":"GLM.ProbitLink","text":"ProbitLink\n\nA Link01 whose linkinv is the c.d.f. of the standard normal distribution, Distributions.Normal().\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.SqrtLink","page":"API","title":"GLM.SqrtLink","text":"SqrtLink\n\nA Link defined as η = √μ\n\n\n\n\n\n","category":"type"},{"location":"api/#GLM.linkfun","page":"API","title":"GLM.linkfun","text":"GLM.linkfun(L::Link, μ::Real)\n\nReturn η, the value of the linear predictor for link L at mean μ.\n\nExamples\n\njulia> μ = inv(10):inv(5):1\n0.1:0.2:0.9\n\njulia> show(linkfun.(LogitLink(), μ))\n[-2.197224577336219, -0.8472978603872036, 0.0, 0.8472978603872034, 2.1972245773362196]\n\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.linkinv","page":"API","title":"GLM.linkinv","text":"GLM.linkinv(L::Link, η::Real)\n\nReturn μ, the mean value, for link L at linear predictor value η.\n\nExamples\n\njulia> μ = 0.1:0.2:1\n0.1:0.2:0.9\n\njulia> η = logit.(μ);\n\n\njulia> linkinv.(LogitLink(), η) ≈ μ\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.mueta","page":"API","title":"GLM.mueta","text":"GLM.mueta(L::Link, η::Real)\n\nReturn the derivative of linkinv, dμ/dη, for link L at linear predictor value η.\n\nExamples\n\njulia> mueta(LogitLink(), 0.0)\n0.25\n\njulia> mueta(CloglogLink(), 0.0) ≈ 0.36787944117144233\ntrue\n\njulia> mueta(LogLink(), 2.0) ≈ 7.38905609893065\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.inverselink","page":"API","title":"GLM.inverselink","text":"GLM.inverselink(L::Link, η::Real)\n\nReturn a 3-tuple of the inverse link, the derivative of the inverse link, and when appropriate, the variance function μ*(1 - μ).\n\nThe variance function is returned as NaN unless the range of μ is (0, 1)\n\nExamples\n\njulia> GLM.inverselink(LogitLink(), 0.0)\n(0.5, 0.5, 0.25)\n\njulia> μ, oneminusμ, variance = GLM.inverselink(CloglogLink(), 0.0);\n\n\n\njulia> μ + oneminusμ ≈ 1\ntrue\n\njulia> μ*(1 - μ) ≈ variance\nfalse\n\njulia> isnan(last(GLM.inverselink(LogLink(), 2.0)))\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.canonicallink","page":"API","title":"GLM.canonicallink","text":"canonicallink(D::Distribution)\n\nReturn the canonical link for distribution D, which must be in the exponential family.\n\nExamples\n\njulia> canonicallink(Bernoulli())\nLogitLink()\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.glmvar","page":"API","title":"GLM.glmvar","text":"GLM.glmvar(D::Distribution, μ::Real)\n\nReturn the value of the variance function for D at μ\n\nThe variance of D at μ is the product of the dispersion parameter, ϕ, which does not depend on μ and the value of glmvar.  In other words glmvar returns the factor of the variance that depends on μ.\n\nExamples\n\njulia> μ = 1/6:1/3:1;\n\njulia> glmvar.(Normal(), μ)    # constant for Normal()\n3-element Vector{Float64}:\n 1.0\n 1.0\n 1.0\n\njulia> glmvar.(Bernoulli(), μ) ≈ μ .* (1 .- μ)\ntrue\n\njulia> glmvar.(Poisson(), μ) == μ\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.mustart","page":"API","title":"GLM.mustart","text":"GLM.mustart(D::Distribution, y, wt)\n\nReturn a starting value for μ.\n\nFor some distributions it is appropriate to set μ = y to initialize the IRLS algorithm but for others, notably the Bernoulli, the values of y are not allowed as values of μ and must be modified.\n\nExamples\n\njulia> GLM.mustart(Bernoulli(), 0.0, 1) ≈ 1/4\ntrue\n\njulia> GLM.mustart(Bernoulli(), 1.0, 1) ≈ 3/4\ntrue\n\njulia> GLM.mustart(Binomial(), 0.0, 10) ≈ 1/22\ntrue\n\njulia> GLM.mustart(Normal(), 0.0, 1) ≈ 0\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.devresid","page":"API","title":"GLM.devresid","text":"devresid(D, y, μ::Real)\n\nReturn the squared deviance residual of μ from y for distribution D\n\nThe deviance of a GLM can be evaluated as the sum of the squared deviance residuals.  This is the principal use for these values.  The actual deviance residual, say for plotting, is the signed square root of this value\n\nsign(y - μ) * sqrt(devresid(D, y, μ))\n\nExamples\n\njulia> devresid(Normal(), 0, 0.25) ≈ abs2(0.25)\ntrue\n\njulia> devresid(Bernoulli(), 1, 0.75) ≈ -2*log(0.75)\ntrue\n\njulia> devresid(Bernoulli(), 0, 0.25) ≈ -2*log1p(-0.25)\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.dispersion_parameter","page":"API","title":"GLM.dispersion_parameter","text":"GLM.dispersion_parameter(D)\n\nDoes distribution D have a separate dispersion parameter, ϕ?\n\nReturns false for the Bernoulli, Binomial and Poisson distributions, true otherwise.\n\nExamples\n\njulia> show(GLM.dispersion_parameter(Normal()))\ntrue\njulia> show(GLM.dispersion_parameter(Bernoulli()))\nfalse\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.loglik_obs","page":"API","title":"GLM.loglik_obs","text":"GLM.loglik_obs(D, y, μ, wt, ϕ)\n\nReturns wt * logpdf(D(μ, ϕ), y) where the parameters of D are derived from μ and ϕ.\n\nThe wt argument is a multiplier of the result except in the case of the Binomial where wt is the number of trials and μ is the proportion of successes.\n\nThe loglikelihood of a fitted model is the sum of these values over all the observations.\n\n\n\n\n\n","category":"function"},{"location":"api/#GLM.cancancel","page":"API","title":"GLM.cancancel","text":"cancancel(r::GlmResp{V,D,L})\n\nReturns true if dμ/dη for link L is the variance function for distribution D\n\nWhen L is the canonical link for D the derivative of the inverse link is a multiple of the variance function for D.  If they are the same a numerator and denominator term in the expression for the working weights will cancel.\n\n\n\n\n\n","category":"function"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"DocTestSetup = quote\n    using CategoricalArrays, DataFrames, Distributions, GLM, RDatasets\nend","category":"page"},{"location":"examples/#Linear-regression","page":"Examples","title":"Linear regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> using DataFrames, GLM\n\njulia> data = DataFrame(X=[1,2,3], Y=[2,4,7])\n3×2 DataFrame\n Row │ X      Y\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      2\n   2 │     2      4\n   3 │     3      7\n\njulia> ols = lm(@formula(Y ~ X), data)\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nY ~ 1 + X\n\nCoefficients:\n─────────────────────────────────────────────────────────────────────────\n                 Coef.  Std. Error      t  Pr(>|t|)  Lower 95%  Upper 95%\n─────────────────────────────────────────────────────────────────────────\n(Intercept)  -0.666667    0.62361   -1.07    0.4788   -8.59038    7.25704\nX             2.5         0.288675   8.66    0.0732   -1.16797    6.16797\n─────────────────────────────────────────────────────────────────────────\n\njulia> round.(stderror(ols), digits=5)\n2-element Vector{Float64}:\n 0.62361\n 0.28868\n\njulia> round.(predict(ols), digits=5)\n3-element Vector{Float64}:\n 1.83333\n 4.33333\n 6.83333","category":"page"},{"location":"examples/#Probit-regression","page":"Examples","title":"Probit regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> data = DataFrame(X=[1,2,2], Y=[1,0,1])\n3×2 DataFrame\n Row │ X      Y\n     │ Int64  Int64\n─────┼──────────────\n   1 │     1      1\n   2 │     2      0\n   3 │     2      1\n\njulia> probit = glm(@formula(Y ~ X), data, Binomial(), ProbitLink())\nStatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, Binomial{Float64}, ProbitLink}, GLM.DensePredChol{Float64, LinearAlgebra.Cholesky{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nY ~ 1 + X\n\nCoefficients:\n────────────────────────────────────────────────────────────────────────\n                Coef.  Std. Error      z  Pr(>|z|)  Lower 95%  Upper 95%\n────────────────────────────────────────────────────────────────────────\n(Intercept)   9.63839     293.909   0.03    0.9738   -566.414    585.69\nX            -4.81919     146.957  -0.03    0.9738   -292.849    283.211\n────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"examples/#Negative-binomial-regression","page":"Examples","title":"Negative binomial regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> using GLM, RDatasets\n\njulia> quine = dataset(\"MASS\", \"quine\")\n146×5 DataFrame\n Row │ Eth   Sex   Age   Lrn   Days\n     │ Cat…  Cat…  Cat…  Cat…  Int32\n─────┼───────────────────────────────\n   1 │ A     M     F0    SL        2\n   2 │ A     M     F0    SL       11\n   3 │ A     M     F0    SL       14\n   4 │ A     M     F0    AL        5\n   5 │ A     M     F0    AL        5\n   6 │ A     M     F0    AL       13\n   7 │ A     M     F0    AL       20\n   8 │ A     M     F0    AL       22\n  ⋮  │  ⋮     ⋮     ⋮     ⋮      ⋮\n 140 │ N     F     F3    AL        3\n 141 │ N     F     F3    AL        3\n 142 │ N     F     F3    AL        5\n 143 │ N     F     F3    AL       15\n 144 │ N     F     F3    AL       18\n 145 │ N     F     F3    AL       22\n 146 │ N     F     F3    AL       37\n                     131 rows omitted\n\njulia> nbrmodel = glm(@formula(Days ~ Eth+Sex+Age+Lrn), quine, NegativeBinomial(2.0), LogLink())\nStatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, NegativeBinomial{Float64}, LogLink}, GLM.DensePredChol{Float64, LinearAlgebra.Cholesky{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nDays ~ 1 + Eth + Sex + Age + Lrn\n\nCoefficients:\n────────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%\n────────────────────────────────────────────────────────────────────────────\n(Intercept)   2.88645      0.227144  12.71    <1e-36   2.44125     3.33164\nEth: N       -0.567515     0.152449  -3.72    0.0002  -0.86631    -0.26872\nSex: M        0.0870771    0.159025   0.55    0.5840  -0.224606    0.398761\nAge: F1      -0.445076     0.239087  -1.86    0.0627  -0.913678    0.0235251\nAge: F2       0.0927999    0.234502   0.40    0.6923  -0.366816    0.552416\nAge: F3       0.359485     0.246586   1.46    0.1449  -0.123814    0.842784\nLrn: SL       0.296768     0.185934   1.60    0.1105  -0.0676559   0.661191\n────────────────────────────────────────────────────────────────────────────\n\njulia> nbrmodel = negbin(@formula(Days ~ Eth+Sex+Age+Lrn), quine, LogLink())\nStatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, NegativeBinomial{Float64}, LogLink}, GLM.DensePredChol{Float64, LinearAlgebra.Cholesky{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nDays ~ 1 + Eth + Sex + Age + Lrn\n\nCoefficients:\n────────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      z  Pr(>|z|)   Lower 95%   Upper 95%\n────────────────────────────────────────────────────────────────────────────\n(Intercept)   2.89453      0.227415  12.73    <1e-36   2.4488      3.34025\nEth: N       -0.569341     0.152656  -3.73    0.0002  -0.868541   -0.270141\nSex: M        0.0823881    0.159209   0.52    0.6048  -0.229655    0.394431\nAge: F1      -0.448464     0.238687  -1.88    0.0603  -0.916281    0.0193536\nAge: F2       0.0880506    0.235149   0.37    0.7081  -0.372834    0.548935\nAge: F3       0.356955     0.247228   1.44    0.1488  -0.127602    0.841513\nLrn: SL       0.292138     0.18565    1.57    0.1156  -0.0717297   0.656006\n────────────────────────────────────────────────────────────────────────────\n\njulia> println(\"Estimated theta = \", round(nbrmodel.model.rr.d.r, digits=5))\nEstimated theta = 1.27489\n","category":"page"},{"location":"examples/#Julia-and-R-comparisons","page":"Examples","title":"Julia and R comparisons","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"An example of a simple linear model in R is","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"> coef(summary(lm(optden ~ carb, Formaldehyde)))\n               Estimate  Std. Error    t value     Pr(>|t|)\n(Intercept) 0.005085714 0.007833679  0.6492115 5.515953e-01\ncarb        0.876285714 0.013534536 64.7444207 3.409192e-07","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The corresponding model with the GLM package is","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> using GLM, RDatasets\n\njulia> form = dataset(\"datasets\", \"Formaldehyde\")\n6×2 DataFrame\n Row │ Carb     OptDen\n     │ Float64  Float64\n─────┼──────────────────\n   1 │     0.1    0.086\n   2 │     0.3    0.269\n   3 │     0.5    0.446\n   4 │     0.6    0.538\n   5 │     0.7    0.626\n   6 │     0.9    0.782\n\njulia> lm1 = fit(LinearModel, @formula(OptDen ~ Carb), form)\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nOptDen ~ 1 + Carb\n\nCoefficients:\n───────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n───────────────────────────────────────────────────────────────────────────\n(Intercept)  0.00508571  0.00783368   0.65    0.5516  -0.0166641  0.0268355\nCarb         0.876286    0.0135345   64.74    <1e-06   0.838708   0.913864\n───────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"A more complex example in R is","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"> coef(summary(lm(sr ~ pop15 + pop75 + dpi + ddpi, LifeCycleSavings)))\n                 Estimate   Std. Error    t value     Pr(>|t|)\n(Intercept) 28.5660865407 7.3545161062  3.8841558 0.0003338249\npop15       -0.4611931471 0.1446422248 -3.1885098 0.0026030189\npop75       -1.6914976767 1.0835989307 -1.5609998 0.1255297940\ndpi         -0.0003369019 0.0009311072 -0.3618293 0.7191731554\nddpi         0.4096949279 0.1961971276  2.0881801 0.0424711387","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"with the corresponding Julia code","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> LifeCycleSavings = dataset(\"datasets\", \"LifeCycleSavings\")\n50×6 DataFrame\n Row │ Country         SR       Pop15    Pop75    DPI      DDPI\n     │ String15        Float64  Float64  Float64  Float64  Float64\n─────┼─────────────────────────────────────────────────────────────\n   1 │ Australia         11.43    29.35     2.87  2329.68     2.87\n   2 │ Austria           12.07    23.32     4.41  1507.99     3.93\n   3 │ Belgium           13.17    23.8      4.43  2108.47     3.82\n   4 │ Bolivia            5.75    41.89     1.67   189.13     0.22\n   5 │ Brazil            12.88    42.19     0.83   728.47     4.56\n   6 │ Canada             8.79    31.72     2.85  2982.88     2.43\n   7 │ Chile              0.6     39.74     1.34   662.86     2.67\n   8 │ China             11.9     44.75     0.67   289.52     6.51\n  ⋮  │       ⋮            ⋮        ⋮        ⋮        ⋮        ⋮\n  44 │ United States      7.56    29.81     3.43  4001.89     2.45\n  45 │ Venezuela          9.22    46.4      0.9    813.39     0.53\n  46 │ Zambia            18.56    45.25     0.56   138.33     5.14\n  47 │ Jamaica            7.72    41.12     1.73   380.47    10.23\n  48 │ Uruguay            9.24    28.13     2.72   766.54     1.88\n  49 │ Libya              8.89    43.69     2.07   123.58    16.71\n  50 │ Malaysia           4.71    47.2      0.66   242.69     5.08\n                                                    35 rows omitted\n\njulia> fm2 = fit(LinearModel, @formula(SR ~ Pop15 + Pop75 + DPI + DDPI), LifeCycleSavings)\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nSR ~ 1 + Pop15 + Pop75 + DPI + DDPI\n\nCoefficients:\n─────────────────────────────────────────────────────────────────────────────────\n                    Coef.   Std. Error      t  Pr(>|t|)    Lower 95%    Upper 95%\n─────────────────────────────────────────────────────────────────────────────────\n(Intercept)  28.5661       7.35452       3.88    0.0003  13.7533      43.3788\nPop15        -0.461193     0.144642     -3.19    0.0026  -0.752518    -0.169869\nPop75        -1.6915       1.0836       -1.56    0.1255  -3.87398      0.490983\nDPI          -0.000336902  0.000931107  -0.36    0.7192  -0.00221225   0.00153844\nDDPI          0.409695     0.196197      2.09    0.0425   0.0145336    0.804856\n─────────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The glm function (or equivalently, fit(GeneralizedLinearModel, ...)) works similarly to the R glm function except that the family argument is replaced by a Distribution type and, optionally, a Link type. The first example from ?glm in R is","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"glm> ## Dobson (1990) Page 93: Randomized Controlled Trial : (slightly modified)\nglm> counts <- c(18,17,15,20,10,21,25,13,13)\n\nglm> outcome <- gl(3,1,9)\n\nglm> treatment <- gl(3,3)\n\nglm> print(d.AD <- data.frame(treatment, outcome, counts))\n  treatment outcome counts\n1         1       1     18\n2         1       2     17\n3         1       3     15\n4         2       1     20\n5         2       2     10\n6         2       3     21\n7         3       1     25\n8         3       2     13\n9         3       3     13\n\nglm> glm.D93 <- glm(counts ~ outcome + treatment, family=poisson())\n\nglm> anova(glm.D93)\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: counts\n\nTerms added sequentially (first to last)\n\n\n          Df Deviance Resid. Df Resid. Dev\nNULL                          8    10.3928\noutcome    2   5.2622         6     5.1307\ntreatment  2   0.0132         4     5.1175\n\nglm> ## No test:\nglm> summary(glm.D93)\n\nCall:\nglm(formula = counts ~ outcome + treatment, family = poisson())\n\nDeviance Residuals:\n      1        2        3        4        5        6        7        8        9\n-0.6122   1.0131  -0.2819  -0.2498  -0.9784   1.0777   0.8162  -0.1155  -0.8811\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   3.0313     0.1712  17.711   <2e-16 ***\noutcome2     -0.4543     0.2022  -2.247   0.0246 *\noutcome3     -0.2513     0.1905  -1.319   0.1870\ntreatment2    0.0198     0.1990   0.100   0.9207\ntreatment3    0.0198     0.1990   0.100   0.9207\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 10.3928  on 8  degrees of freedom\nResidual deviance:  5.1175  on 4  degrees of freedom\nAIC: 56.877\n\nNumber of Fisher Scoring iterations: 4","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"In Julia this becomes","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"julia> using DataFrames, CategoricalArrays, GLM\n\njulia> dobson = DataFrame(Counts    = [18.,17,15,20,10,21,25,13,13],\n                          Outcome   = categorical([1,2,3,1,2,3,1,2,3]),\n                          Treatment = categorical([1,1,1,2,2,2,3,3,3]))\n9×3 DataFrame\n Row │ Counts   Outcome  Treatment\n     │ Float64  Cat…     Cat…\n─────┼─────────────────────────────\n   1 │    18.0  1        1\n   2 │    17.0  2        1\n   3 │    15.0  3        1\n   4 │    20.0  1        2\n   5 │    10.0  2        2\n   6 │    21.0  3        2\n   7 │    25.0  1        3\n   8 │    13.0  2        3\n   9 │    13.0  3        3\n\njulia> gm1 = fit(GeneralizedLinearModel, @formula(Counts ~ Outcome + Treatment), dobson, Poisson())\nStatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, Poisson{Float64}, LogLink}, GLM.DensePredChol{Float64, LinearAlgebra.Cholesky{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\nCounts ~ 1 + Outcome + Treatment\n\nCoefficients:\n────────────────────────────────────────────────────────────────────────────\n                   Coef.  Std. Error      z  Pr(>|z|)  Lower 95%   Upper 95%\n────────────────────────────────────────────────────────────────────────────\n(Intercept)    3.03128      0.171155  17.71    <1e-69   2.69582    3.36674\nOutcome: 2    -0.454255     0.202171  -2.25    0.0246  -0.850503  -0.0580079\nOutcome: 3    -0.251314     0.190476  -1.32    0.1870  -0.624641   0.122012\nTreatment: 2   0.0198026    0.199017   0.10    0.9207  -0.370264   0.409869\nTreatment: 3   0.0198026    0.199017   0.10    0.9207  -0.370264   0.409869\n────────────────────────────────────────────────────────────────────────────\n\njulia> round(deviance(gm1), digits=5)\n5.11746","category":"page"},{"location":"#GLM.jl-Manual","page":"Home","title":"GLM.jl Manual","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Linear and generalized linear models in Julia","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pkg.add(\"GLM\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"will install this package and its dependencies, which includes the Distributions package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The RDatasets package is useful for fitting models on standard R datasets to compare the results with those from R.","category":"page"},{"location":"#Fitting-GLM-models","page":"Home","title":"Fitting GLM models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Two methods can be used to fit a Generalized Linear Model (GLM): glm(formula, data, family, link) and glm(X, y, family, link). Their arguments must be:","category":"page"},{"location":"","page":"Home","title":"Home","text":"formula: a StatsModels.jl Formula object referring to columns in data; for example, if column names are :Y, :X1, and :X2, then a valid formula is @formula(Y ~ X1 + X2)\ndata: a table in the Tables.jl definition, e.g. a data frame; rows with missing values are ignored\nX a matrix holding values of the dependent variable(s) in columns\ny a vector holding values of the independent variable (including if appropriate the intercept)\nfamily: chosen from Bernoulli(), Binomial(), Gamma(), Normal(), Poisson(), or NegativeBinomial(θ)\nlink: chosen from the list below, for example, LogitLink() is a valid link for the Binomial() family","category":"page"},{"location":"","page":"Home","title":"Home","text":"Typical distributions for use with glm and their canonical link functions are","category":"page"},{"location":"","page":"Home","title":"Home","text":"       Bernoulli (LogitLink)\n        Binomial (LogitLink)\n           Gamma (InverseLink)\n InverseGaussian (InverseSquareLink)\nNegativeBinomial (NegativeBinomialLink, often used with LogLink)\n          Normal (IdentityLink)\n         Poisson (LogLink)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently the available Link types are","category":"page"},{"location":"","page":"Home","title":"Home","text":"CauchitLink\nCloglogLink\nIdentityLink\nInverseLink\nInverseSquareLink\nLogitLink\nLogLink\nNegativeBinomialLink\nProbitLink\nSqrtLink","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the canonical link for negative binomial regression is NegativeBinomialLink, but in practice one typically uses LogLink. The NegativeBinomial distribution belongs to the exponential family only if θ (the shape parameter) is fixed, thus θ has to be provided if we use glm with NegativeBinomial family. If one would like to also estimate θ, then negbin(formula, data, link) should be used instead.","category":"page"},{"location":"","page":"Home","title":"Home","text":"An intercept is included in any GLM by default.","category":"page"},{"location":"#Categorical-variables","page":"Home","title":"Categorical variables","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Categorical variables will be dummy coded by default if they are non-numeric or if they are CategoricalVectors within a Tables.jl table (DataFrame, JuliaDB table, named tuple of vectors, etc). Alternatively, you can pass an explicit contrasts argument if you would like a different contrast coding system or if you are not using DataFrames.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The response (dependent) variable may not be categorical.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using a CategoricalVector constructed with categorical or categorical!:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using CategoricalArrays, DataFrames, GLM, StableRNGs\n\njulia> rng = StableRNG(1); # Ensure example can be reproduced\n\njulia> data = DataFrame(y = rand(rng, 100), x = categorical(repeat([1, 2, 3, 4], 25)));\n\n\njulia> lm(@formula(y ~ x), data)\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\ny ~ 1 + x\n\nCoefficients:\n───────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n───────────────────────────────────────────────────────────────────────────\n(Intercept)   0.490985    0.0564176   8.70    <1e-13   0.378997    0.602973\nx: 2          0.0527655   0.0797865   0.66    0.5100  -0.105609    0.21114\nx: 3          0.0955446   0.0797865   1.20    0.2341  -0.0628303   0.25392\nx: 4         -0.032673    0.0797865  -0.41    0.6831  -0.191048    0.125702\n───────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using contrasts:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using StableRNGs\n\njulia> data = DataFrame(y = rand(StableRNG(1), 100), x = repeat([1, 2, 3, 4], 25));\n\njulia> lm(@formula(y ~ x), data, contrasts = Dict(:x => DummyCoding()))\nStatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n\ny ~ 1 + x\n\nCoefficients:\n───────────────────────────────────────────────────────────────────────────\n                  Coef.  Std. Error      t  Pr(>|t|)   Lower 95%  Upper 95%\n───────────────────────────────────────────────────────────────────────────\n(Intercept)   0.490985    0.0564176   8.70    <1e-13   0.378997    0.602973\nx: 2          0.0527655   0.0797865   0.66    0.5100  -0.105609    0.21114\nx: 3          0.0955446   0.0797865   1.20    0.2341  -0.0628303   0.25392\nx: 4         -0.032673    0.0797865  -0.41    0.6831  -0.191048    0.125702\n───────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"#Comparing-models-with-F-test","page":"Home","title":"Comparing models with F-test","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Comparisons between two or more linear models can be performed using the ftest function, which computes an F-test between each pair of subsequent models and reports fit statistics:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using DataFrames, GLM, StableRNGs\n\njulia> data = DataFrame(y = (1:50).^2 .+ randn(StableRNG(1), 50), x = 1:50);\n\njulia> ols_lin = lm(@formula(y ~ x), data);\n\njulia> ols_sq = lm(@formula(y ~ x + x^2), data);\n\njulia> ftest(ols_lin.model, ols_sq.model)\nF-test: 2 models fitted on 50 observations\n─────────────────────────────────────────────────────────────────────────────────\n     DOF  ΔDOF           SSR           ΔSSR      R²     ΔR²            F*   p(>F)\n─────────────────────────────────────────────────────────────────────────────────\n[1]    3        1731979.2266                 0.9399\n[2]    4     1       40.7581  -1731938.4685  1.0000  0.0601  1997177.0357  <1e-99\n─────────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"#Methods-applied-to-fitted-models","page":"Home","title":"Methods applied to fitted models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Many of the methods provided by this package have names similar to those in R.","category":"page"},{"location":"","page":"Home","title":"Home","text":"coef: extract the estimates of the coefficients in the model\ndeviance: measure of the model fit, weighted residual sum of squares for lm's\ndof_residual: degrees of freedom for residuals, when meaningful\nglm: fit a generalized linear model (an alias for fit(GeneralizedLinearModel, ...))\nlm: fit a linear model (an alias for fit(LinearModel, ...))\nr2: R² of a linear model or pseudo-R² of a generalized linear model\nstderror: standard errors of the coefficients\nvcov: estimated variance-covariance matrix of the coefficient estimates\npredict : obtain predicted values of the dependent variable from the fitted model\nresiduals: get the vector of residuals from the fitted model","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that the canonical link for negative binomial regression is NegativeBinomialLink, but in practice one typically uses LogLink.","category":"page"},{"location":"#Separation-of-response-object-and-predictor-object","page":"Home","title":"Separation of response object and predictor object","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The general approach in this code is to separate functionality related to the response from that related to the linear predictor.  This allows for greater generality by mixing and matching different subtypes of the abstract type LinPred and the abstract type ModResp.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A LinPred type incorporates the parameter vector and the model matrix.  The parameter vector is a dense numeric vector but the model matrix can be dense or sparse.  A LinPred type must incorporate some form of a decomposition of the weighted model matrix that allows for the solution of a system X'W * X * delta=X'wres where W is a diagonal matrix of \"X weights\", provided as a vector of the square roots of the diagonal elements, and wres is a weighted residual vector.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently there are two dense predictor types, DensePredQR and DensePredChol, and the usual caveats apply.  The Cholesky version is faster but somewhat less accurate than that QR version. The skeleton of a distributed predictor type is in the code but not yet fully fleshed out.  Because Julia by default uses OpenBLAS, which is already multi-threaded on multicore machines, there may not be much advantage in using distributed predictor types.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A ModResp type must provide methods for the wtres and sqrtxwts generics.  Their values are the arguments to the updatebeta methods of the LinPred types.  The Float64 value returned by updatedelta is the value of the convergence criterion.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Similarly, LinPred types must provide a method for the linpred generic.  In general linpred takes an instance of a LinPred type and a step factor.  Methods that take only an instance of a LinPred type use a default step factor of 1.  The value of linpred is the argument to the updatemu method for ModResp types.  The updatemu method returns the updated deviance.","category":"page"}]
}
